---
title: "fDOM 2023 hindcasts"
author: "Dexter Howard"
date: "2024-02-19"
output: html_document
---


```{r, message = F}
library(tidyverse)
```

## Set up data

get local targets data 

```{r}
### S3 links 
targets_url <- "https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/targets/project_id=vera4cast/duration=P1D/daily-insitu-targets.csv.gz"

# met_url <- "https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/targets/project_id=vera4cast/duration=P1D/daily-met-targets.csv.gz"

### met data 
# met_targets <- readr::read_csv(met_url, show_col_types = FALSE) |> 
#   filter(datetime >= ymd("2022-01-01"),
#          datetime < ymd("2024-04-01"),
#          variable %in% c("ShortwaveRadiationUp_Wm2_mean", "Rain_mm_sum"))

# water Q data
fcr_waterQ <- readr::read_csv(targets_url, show_col_types = FALSE) |>
  filter(datetime >= ymd("2022-01-01"),
         datetime < ymd("2024-04-01"),
         site_id == "fcre",
         depth_m == 1.6,
         variable %in% c("fDOM_QSU_mean", "Temp_C_mean"))


bvr_waterQ <- readr::read_csv(targets_url, show_col_types = FALSE) |>
  filter(datetime >= ymd("2022-01-01"),
         datetime < ymd("2024-04-01"),
         site_id == "bvre",
         depth_m == 1.5,
         variable %in% c("fDOM_QSU_mean", "Temp_C_mean"))

```


load and format NOAA forecasts

```{r}
#### Getting NOAA forecasts from 2020-09-25 to 2024-02-18
# old_met_bucket <- arrow::s3_bucket(file.path("bio230121-bucket01/vt_backup/drivers/noaa/gefs-v12-reprocess/stage2/"),
#                                          endpoint_override = 'renc.osn.xsede.org',
#                                          anonymous = TRUE)
# 
# noaa_old_daily <- arrow::open_dataset(old_met_bucket) |>
#   dplyr::filter(
#        site_id == 'fcre',  #filtering by bvre returns the same forecasts 
#        variable %in% c("precipitation_flux", "surface_downwelling_shortwave_flux_in_air")) |>
#   mutate(datetime_date = as.Date(datetime)) |>
#   group_by(reference_datetime, datetime_date, variable, parameter) |>
#   summarise(prediction = mean(prediction, na.rm = T), .groups = "drop") |> 
#   dplyr::collect()

#write.csv(noaa_old_daily, "C:/Users/dwh18/OneDrive/Desktop/R_Projects/fDOM_forecasting/Data/GeneratedData/FCR_NOAA_stage2_dailyaverage_25sep20-18feb24.csv", row.names = F)

noaa_daily <- read.csv("../Data/GeneratedData/FCR_NOAA_stage2_dailyaverage_25sep20-18feb24.csv")
noaa_dailyz <- noaa_daily |> 
  filter(parameter <= 30)

```

load and format FLARE water temp forecasts 

```{r}
###This gets water temp forecasts w/ reference datetimes from 2022-10-02 to 2024-02-18

##FCR
# fcr_backup_forecasts <- arrow::s3_bucket(file.path("bio230121-bucket01/vt_backup/forecasts/parquet/site_id=fcre/"),
#                                   endpoint_override = 'renc.osn.xsede.org',
#                                   anonymous = TRUE)
# 
# fcr_df_flare_old <- arrow::open_dataset(fcr_backup_forecasts) |>
#   filter(depth %in% c(1.5), #no 1.6
#          variable == "temperature",
#          parameter <= 31,
#          model_id == "test_runS3" #other models for FCR, this is the only one for BVR in backups bucket
#          ) |> 
#   dplyr::collect()
# 
# write.csv(fcr_df_flare_old, "C:/Users/dwh18/OneDrive/Desktop/R_Projects/fDOM_forecasting/Data/GeneratedData/FCR_FLARE_7nov22-18feb24.csv", row.names = F)

fcr_flare <- read.csv("../Data/GeneratedData/FCR_FLARE_7nov22-18feb24.csv")

fcr_flare <- fcr_flare |> 
  rename(datetime_date = datetime) |> 
  filter(parameter <= 31) |> 
  filter(as.Date(reference_datetime) > ymd("2022-11-07") ) #remove odd date that has dates one month behind reference datetime


## BVR 
# bvr_backup_forecasts <- arrow::s3_bucket(file.path("bio230121-bucket01/vt_backup/forecasts/parquet/site_id=bvre/"),
#                                   endpoint_override = 'renc.osn.xsede.org',
#                                   anonymous = TRUE)
# 
# bvr_df_flare_old <- arrow::open_dataset(bvr_backup_forecasts) |>
#   filter(depth %in% c(1.5), 
#          variable == "temperature",
#          parameter <= 31
#          ) |>  
#   dplyr::collect()
# 
#
# write.csv(bvr_df_flare_old, "C:/Users/dwh18/OneDrive/Desktop/R_Projects/fDOM_forecasting/Data/GeneratedData/BVR_FLARE_7nov22-18feb24.csv", row.names = F)

bvr_flare <- read.csv("../Data/GeneratedData/BVR_FLARE_7nov22-18feb24.csv")


```



## Functions

helper functions 
```{r}
##function to pull current value 
current_value <- function(dataframe, variable, start_date){
  
  value <- dataframe |> 
  mutate(datetime = as.Date(datetime)) |> 
  filter(datetime == start_date,
         variable == variable) |> 
  pull(observation)
  
  return(value)
}
 
#function to generate 30 ensembles of fDOM IC based on standard deviation arround current observation
get_IC_uncert <- function(curr_fdom, n_members, ic_sd = 0.1){
  rnorm(n = n_members, mean = curr_fdom, sd = ic_sd)
}

```




## trying function to run forecasts for new day at FCR

function to run forecast and recalibrate every 90 days 

```{r}

forecast_date <- ymd("2023-04-24")
model_id <- "example_fDOM_AR_dwh"
targets_url <- "https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/targets/project_id=vera4cast/duration=P1D/daily-insitu-targets.csv.gz"
var <- "fDOM_QSU_mean"
site <- "fcre"
forecast_depths <- 1.6
project_id <- "vera4cast"

# site_list <- read_csv("https://raw.githubusercontent.com/LTREB-reservoirs/vera4cast/main/vera4cast_field_site_metadata.csv",
#                       show_col_types = FALSE)
# 
# water_temp_4cast_url <- "s3://anonymous@bio230121-bucket01/vera4cast/forecasts/parquet/project_id=vera4cast/duration=P1D/variable=Temp_C_mean?endpoint_override=renc.osn.xsede.org"

water_temp_4cast_data <- fcr_flare
noaa_4cast <- noaa_daily

n_members <- 31
forecast_horizon <- 16
output_folder <- "z"

# generate_example_forecast

# fdom_forecast_full_uncert <- function(variable = "fDOM_QSU_mean", forecast_start_date, n_members, forecast_horizon,
#                           fdom_IC_df, noaa_df, flare_df, output_folder)
  
generate_fDOM_forecast <- function(forecast_date, # a recommended argument so you can pass the date to the function
                                   forecast_horizon,
                                   n_members,
                                   output_folder,
                                   
                                      model_id,
                                      targets_url, # where are the targets you are forecasting?
                                      water_temp_4cast_data,
                                      noaa_4cast,
                                      # water_temp_4cast_url, #get url for water temp used as covariate
                                      # weather_forecast,
                                      var, # what variable(s)?
                                      site, # what site(s),
                                      forecast_depths = 'focal',
                                      project_id = 'vera4cast') {

  # Put your forecast generating code in here, and add/remove arguments as needed.
  # Forecast date should not be hard coded
  # This is an example function that also grabs weather forecast information to be used as co-variates

  if (site == 'fcre' & forecast_depths == 'focal') {
    forecast_depths <- 1.6
  }

  if (site == 'bvre' & forecast_depths == 'focal') {
    forecast_depths <- 1.5
  }
  #-------------------------------------

  # Get targets
  message('Getting targets')
  targets <- readr::read_csv(targets_url, show_col_types = F) |>
    filter(variable %in% var,
           site_id %in% site,
           depth_m %in% forecast_depths,
           datetime <= forecast_date)
  #-------------------------------------

  # Get the weather data
  message('Getting weather')

    head(noaa_4cast)
  
  # split it into historic and future

  historic_weather <- noaa_4cast |> 
    filter(reference_datetime == datetime_date) |> #get data from just day of forecast issued
    group_by(reference_datetime, variable) |> 
    summarise(prediction = mean(prediction, na.rm = T), .groups = "drop") |>  #get daily means (from ensembles) for each variable
    pivot_wider(names_from = variable, values_from = prediction) |> 
    filter(ymd(reference_datetime) < forecast_date,
           ymd(reference_datetime) > forecast_date - 90) |> 
    mutate(reference_datetime = as.Date(reference_datetime)) |> 
    rename(datetime = reference_datetime)


  forecast_weather <- noaa_4cast |>
    filter(ymd(reference_datetime) == forecast_date) 
  
  
  #-------------------------------------

  #Get water temp forecasts
  message('Getting water temp 4casts')

  head(water_temp_4cast_data)

  
  # split it into historic and future
  historic_watertemp <- water_temp_4cast_data |>
    filter(as.Date(datetime_date) == as.Date(reference_datetime)) |> 
    # calculate a daily mean (remove ensemble)
    group_by(reference_datetime, variable) |>
    summarise(prediction = mean(prediction, na.rm = T), .groups = "drop") |>
    pivot_wider(names_from = variable, values_from = prediction) |> 
    filter(as.Date(reference_datetime) < forecast_date,
           as.Date(reference_datetime) > forecast_date - 90) |> 
    mutate(reference_datetime = as.Date(reference_datetime)) |> 
    rename(datetime = reference_datetime)


  forecast_watertemp <- water_temp_4cast_data |>
    filter(as.Date(reference_datetime) == forecast_date) 


  #-------------------------------------



  # Fit model
  message('Fitting model')
  
  fit_df <- targets |>
    filter(datetime < forecast_date,
           datetime > forecast_date - 90) |>
    pivot_wider(names_from = variable, values_from = observation) |>
    left_join(historic_weather) |>
    left_join(historic_watertemp) |>
    mutate(fDOM_lag1 = lag(fDOM_QSU_mean, 1),
           precip_lag1 = lag(precipitation_flux, 1))

  fdom_model <- lm(fit_df$fDOM_QSU_mean ~ fit_df$fDOM_lag1 + fit_df$surface_downwelling_shortwave_flux_in_air +
                    fit_df$precipitation_flux + fit_df$precip_lag1 + fit_df$temperature)
  
  model_fit <- summary(fdom_model)

  coeffs <- model_fit$coefficients[,1]
  params_se <- model_fit$coefficients[,2] 
  
  # #### get param uncertainty
  #get param distribtuions for parameter uncertainity
  param_df <- data.frame(beta_int = rnorm(31, coeffs[1], params_se[1]),
                         beta_fdomLag = rnorm(31, coeffs[2], params_se[2]),
                         beta_SW = rnorm(31, coeffs[3], params_se[3]),
                         beta_rain = rnorm(31, coeffs[4], params_se[4]),
                         beta_rainLag = rnorm(31, coeffs[5], params_se[5]),
                         beta_temp = rnorm(31, coeffs[6], params_se[6])
  )
  
  

  ####get process uncertainty
#find residuals
fit_df_noNA <- na.omit(fit_df)
mod <- predict(fdom_model, data = fit_df_noNA)
residuals <- mod - fit_df_noNA$fDOM_QSU_mean
sigma <- sd(residuals, na.rm = TRUE) # Process Uncertainty Noise Std Dev.; this is your sigma


####look at set up for IC uncert 
ic_sd <- 0.1 #adpating from HLWs temp 4cast using 0.1 and detection limit on fDOM sensor being 0.07 QSU
# ic_uc <- rnorm(n = 30, mean = mean(fcr_fdom_2023$observation, na.rm = T), sd = ic_sd)
# hist(ic_uc)
  
# param_df$sigma <- sigma
# param_df$ic_sd <- ic_sd

# return(param_df)
  
  #-------------------------------------

# Set up forecast data frame

message('Make forecast dataframe')

 #establish forecasted dates
  forecasted_dates <- seq(from = ymd(forecast_date), to = ymd(forecast_date) + forecast_horizon, by = "day")

  #get current fdom value
  curr_fdom <- current_value(dataframe = targets,variable = var, start_date = forecast_date)
  
  #set up df of different initial conditions for IC uncert
  ic_df <- tibble(date = rep(as.Date(forecast_date), times = n_members),
                ensemble_member = c(1:n_members),
                forecast_variable = var,
                value = get_IC_uncert(curr_fdom, n_members, ic_sd = 0.1),
                uc_type = "total")

  #set up table to hold forecast output 
forecast_full_unc <- tibble(date = rep(forecasted_dates, times = n_members),
                              ensemble_member = rep(1:n_members, each = length(forecasted_dates)),
                              reference_datetime = forecast_date,
                              Horizon = date - reference_datetime,
                              forecast_variable = var,
                              value = as.double(NA),
                              uc_type = "total") |> 
  rows_update(ic_df, by = c("date","ensemble_member","forecast_variable", "uc_type")) # adding IC uncert
  
  
    #-------------------------------------

  message('Generating forecast')


  #for loop to run forecast 
  for(i in 2:length(forecasted_dates)) {
  
  #pull prediction dataframe for the relevant date
  fdom_pred <- forecast_full_unc %>%
    filter(date == forecasted_dates[i])
  
  #pull driver ensemble for the relevant date; here we are using all 31 NOAA ensemble members
  met_sw_driv <- forecast_weather %>%
    filter(variable == "surface_downwelling_shortwave_flux_in_air") |> 
    filter(ymd(reference_datetime) == forecast_date) |> 
    filter(ymd(datetime_date) == forecasted_dates[i])
  
  met_precip_driv <- forecast_weather %>%
    filter(variable == "precipitation_flux") |> 
    filter(ymd(reference_datetime) == forecast_date) |> 
    filter(ymd(datetime_date) == forecasted_dates[i])
  
    met_precip_lag_driv <- forecast_weather %>%
    filter(variable == "precipitation_flux") |> 
    filter(ymd(reference_datetime) == forecast_date) |> 
    filter(ymd(datetime_date) == forecasted_dates[i-1])
    
  flare_driv <- forecast_watertemp %>%
    filter(as.Date(reference_datetime) == forecast_date) |> 
    filter(ymd(datetime_date) == forecasted_dates[i])
  
  #pull lagged fdom values
  fdom_lag <- forecast_full_unc %>%
    filter(date == forecasted_dates[i-1])
  
  #run model
  fdom_pred$value <- param_df$beta_int + (fdom_lag$value * param_df$beta_fdomLag)  +
     (met_sw_driv$prediction * param_df$beta_SW) + (met_precip_driv$prediction * param_df$beta_rain) + 
     (met_precip_lag_driv$prediction * param_df$beta_rainLag) + (flare_driv$prediction * param_df$beta_temp) +
     rnorm(n = 31, mean = 0, sd = sigma) #process uncert
  
  #insert values back into the forecast dataframe
  forecast_full_unc <- forecast_full_unc %>%
    rows_update(fdom_pred, by = c("date","ensemble_member","forecast_variable","uc_type"))
  
  } #end for loop
  


  #return(forecast_full_unc)
 return(write.csv(forecast_full_unc, "C:/Users/dwh18/Downloads/z.csv", row.names = F))
# return(write.csv(forecast_full_unc, file = paste0("./ASLO_talk_forecast_output/", output_folder, "/forecast_full_unc_", forecast_date, '.csv')))
  
  
  
  
  
  # # Generate forecasts
  # message('Generating forecast')
  # forecast <- (forecast_weather$surface_downwelling_shortwave_flux_in_air * model_fit$coefficients[2]) + model_fit$coefficients[1]
  # 
  # forecast_df <- data.frame(datetime = forecast_weather$datetime,
  #                           reference_datetime = forecast_date,
  #                           model_id = model_id,
  #                           site_id = forecast_weather$site_id,
  #                           parameter = forecast_weather$parameter,
  #                           family = 'ensemble',
  #                           prediction = forecast,
  #                           variable = var,
  #                           depth_m = forecast_depths,
  #                           duration = targets$duration[1],
  #                           project_id = project_id)
  # #-------------------------------------
  # 
  # return(forecast_df)

}  ##### end FEO template function 


##test 4 cast
generate_fDOM_forecast(forecast_date = forecast_date, forecast_horizon = forecast_horizon, n_members = n_members,
                       output_folder = output_folder, model_id = model_id, targets_url = targets_url,
                       water_temp_4cast_data = water_temp_4cast_data, noaa_4cast = noaa_4cast, var = var,
                      site = site, forecast_depths = forecast_depths, project_id = project_id)

read.csv("C:/Users/dwh18/Downloads/z.csv")|> 
  mutate(date = as.Date(date)) |>
    # filter(forecast_date > ymd("2023-01-03")) |>
  ggplot(aes(x = date, y = value, color = as.character(ensemble_member)))+
  geom_line()

```



## get model paramters 

calibrate FCR modle for 2022 and set up param and process uncert

```{r}
#### format data 
fcr_water_wide <- fcr_waterQ |> 
  mutate(datetime = as.Date(datetime)) |> 
  filter(datetime >= ymd("2022-01-01"),
         datetime <= ymd("2022-12-31")) |> 
  pivot_wider(names_from = variable, values_from = observation) |> 
  select(datetime, Temp_C_mean, fDOM_QSU_mean) 

met_wide <- met_targets   |> 
    mutate(datetime = as.Date(datetime)) |> 
  filter(datetime >= ymd("2022-01-01"),
         datetime <= ymd("2022-12-31")) |> 
  pivot_wider(names_from = variable, values_from = observation) |> 
  select(datetime, ShortwaveRadiationUp_Wm2_mean, Rain_mm_sum)

joined_fcr <- left_join(fcr_water_wide, met_wide, by = "datetime") |> 
  mutate(fdom_lag1 = lag(fDOM_QSU_mean),
         rain_lag1 = lag(Rain_mm_sum))

#### calibrate model and get model summary, parameter values and parameter SE
joined_fcr_noNA <- na.omit(joined_fcr)

fdom_model <- lm(fDOM_QSU_mean ~ fdom_lag1 + Temp_C_mean + 
               ShortwaveRadiationUp_Wm2_mean + Rain_mm_sum + rain_lag1,
                  data = joined_fcr_noNA)

fdom_model_summary <- summary(fdom_model)

coeffs <- round(fdom_model_summary$coefficients[,1], 2)
params_se <- fdom_model_summary$coefficients[,2]


#### get param uncertainty
#get param distribtuions for parameter uncertainity 
param_df <- data.frame(beta1 = rnorm(30, coeffs[1], params_se[1]),
                       beta2 = rnorm(30, coeffs[2], params_se[2]),
                       beta3 = rnorm(30, coeffs[3], params_se[3]),
                       beta4 = rnorm(30, coeffs[4], params_se[4]),
                       beta5 = rnorm(30, coeffs[5], params_se[5]),
                       beta6 = rnorm(30, coeffs[6], params_se[6])
                       )
#plot params
param_df |> mutate(colnum = 1) |> select(colnum, everything()) |>  pivot_longer(-1) |> 
  ggplot()+
  geom_density(aes(value))+
  facet_wrap(~name, scales = "free")


####get process uncertainty
#find residuals
mod <- predict(fdom_model, data = joined_fcr_noNA)
residuals <- mod - joined_fcr_noNA$fDOM_QSU_mean
sigma <- sd(residuals, na.rm = TRUE) # Process Uncertainty Noise Std Dev.; this is your sigma


####look at set up for IC uncert 
ic_sd <- 0.1 #adpating from HLWs temp 4cast using 0.1 and detection limit on fDOM sensor being 0.07 QSU
ic_uc <- rnorm(n = 30, mean = mean(fcr_water_wide$fDOM_QSU_mean, na.rm = T), sd = ic_sd)
hist(ic_uc)


```







fDOM function with full uncert

```{r}
#function to run an fdom forecast for one reference day 

fdom_forecast_full_uncert <- function(variable = "fDOM_QSU_mean", forecast_start_date, n_members, forecast_horizon,
                          fdom_IC_df, noaa_df, flare_df, output_folder){
  
    #establish forecasted dates
  forecasted_dates <- seq(from = ymd(forecast_start_date), to = ymd(forecast_start_date) + forecast_horizon, by = "day")

  #get current fdom value
  curr_fdom <- current_value(fdom_IC_df, variable, forecast_start_date)
  
  #set up df of different initial conditions for IC uncert
  ic_df <- tibble(forecast_date = rep(as.Date(forecast_start_date), times = n_members),
                ensemble_member = c(1:n_members),
                forecast_variable = "fdom",
                value = get_IC_uncert(curr_fdom, n_members, ic_sd = 0.1),
                uc_type = "total")

  #set up table to hold forecast output 
forecast_full_unc <- tibble(forecast_date = rep(forecasted_dates, times = n_members),
                              ensemble_member = rep(1:n_members, each = length(forecasted_dates)),
                              reference_datetime = forecast_start_date,
                              Horizon = reference_datetime - forecast_date,
                              forecast_variable = "fdom",
                              value = as.double(NA),
                              uc_type = "total") |> 
  rows_update(ic_df, by = c("forecast_date","ensemble_member","forecast_variable", "uc_type")) # adding IC uncert
  
  
  #for loop to run forecast 
  for(i in 2:length(forecasted_dates)) {
  
  #pull prediction dataframe for the relevant date
  fdom_pred <- forecast_full_unc %>%
    filter(forecast_date == forecasted_dates[i])
  
  #pull driver ensemble for the relevant date; here we are using all 30 NOAA ensemble members
  met_sw_driv <- noaa_df %>%
    filter(variable == "surface_downwelling_shortwave_flux_in_air") |> 
    filter(reference_datetime == forecast_start_date) |> 
    filter(datetime_date == forecasted_dates[i])
  
  met_precip_driv <- noaa_df %>%
    filter(variable == "precipitation_flux") |> 
    filter(reference_datetime == forecast_start_date) |> 
    filter(datetime_date == forecasted_dates[i])
  
    met_precip_lag_driv <- noaa_df %>%
    filter(variable == "precipitation_flux") |> 
    filter(reference_datetime == forecast_start_date) |> 
    filter(datetime_date == forecasted_dates[i-1])
    
  flare_driv <- flare_df %>%
    filter(reference_datetime == forecast_start_date) |> 
    filter(datetime_date == forecasted_dates[i])
  
  #pull lagged fdom values
  fdom_lag <- forecast_full_unc %>%
    filter(forecast_date == forecasted_dates[i-1])
  
  #run model
  fdom_pred$value <- param_df$beta1 + (fdom_lag$value * param_df$beta2) + (flare_driv$prediction * param_df$beta3) +
     (met_sw_driv$prediction * param_df$beta4) + (met_precip_driv$prediction * param_df$beta5) + 
     (met_precip_lag_driv$prediction * param_df$beta6) +
     rnorm(n = 30, mean = 0, sd = sigma) #process uncert
  
  #insert values back into the forecast dataframe
  forecast_full_unc <- forecast_full_unc %>%
    rows_update(fdom_pred, by = c("forecast_date","ensemble_member","forecast_variable","uc_type"))
  
  } #end for loop
  
  
return(write.csv(forecast_full_unc, file = paste0("./ASLO_talk_forecast_output/", output_folder, "/forecast_full_unc_", forecast_start_date, '.csv'))
)
  
}#end function

#### test function 

# ##set up forecast
 forecast_start_date <- ymd("2023-01-02")
n_members <- 30
forecast_horizon <- 16  ## flare forecasts don't seem to go out to 30 days at least in early 2023?
#run function, will genearte csv
fdom_forecast_full_uncert(variable = "fDOM_QSU_mean", forecast_start_date = forecast_start_date,
              n_members = n_members, forecast_horizon = forecast_horizon,
                          fdom_IC_df = fcr_waterQ, noaa_df = noaa_daily, flare_df = fcr_flare,
                             output_folder = "25apr24" )
# 
# #look at plot
# read.csv("./ASLO_forecast_output/forecast_full_unc_2023-01-02.csv") |> 
#   mutate(forecast_date = as.Date(forecast_date)) |> 
#     # filter(forecast_date > ymd("2023-01-03")) |>
#   ggplot(aes(x = forecast_date, y = value, color = as.character(ensemble_member)))+
#   geom_line()


```


## run forecasts 

running for loop over fdom_forecast function
```{r}
## set up dates for for loop
forecast_start_date <- seq(ymd("2023-01-01"), ymd("2023-12-31"), by = "day")

##set up inputs to function
variable <- "fDOM_QSU_mean"
n_members <- 30
forecast_horizon <- 16  ## flare forecasts don't seem to go out to 30 days at least in early 2023? 
fdom_IC_df <- fcr_waterQ
noaa_df <- noaa_daily
flare_df <- fcr_flare


for (j in 1:length(forecast_start_date)) {
  
  fdom_forecast_full_uncert(variable, forecast_start_date[j], 
              n_members, forecast_horizon, fdom_IC_df, noaa_df, flare_df,
              output_folder = "a")


}

#loop broke on 19 Feb and at 16 Dec onwards. 16 Dec is missing input after trimming to 2023 I think. 
#Need to look into issue on 19Feb

```




































## anlayze forecast outputs 

read in forecast outputs
```{r}
#bind forecast outputs into one data frame 
output_all <- list.files(path = "./ASLO_forecast_output/20feb24_1154am", pattern = "*.csv", full.names = T) |> 
  base::lapply(read_csv) |> 
  bind_rows() |> 
  select(-1) #remove row number, need to remove this function

head(output_all)

```

make pdf plot of all forecasts generated 
```{r}
#facet for all forecasts
pdf("./ASLO_forecast_output/all_forecasts.pdf", height = 250)

output_all |> 
  mutate(Horizon = Horizon*-1) |> 
  # filter(reference_datetime == ymd("2023-01-05")) |> 
  ggplot(aes(x = Horizon, y = value, color = as.character(ensemble_member)))+
  geom_line()+
  facet_wrap(~reference_datetime, ncol = 4)+
  guides(color = "none")+
  theme_bw()

dev.off()

```

look at rmse or stats or something

```{r}
#bind in observed fdom 
head(fcr_fdom_2023)
fcr_fdom_2023_forjoin <- fcr_fdom_2023 |> 
  mutate(datetime = as.Date(datetime)) |> 
  select(datetime, observation) |> rename(fdom_observed = observation)

head(output_all)

output_stats <- left_join(output_all, fcr_fdom_2023_forjoin, by = c("forecast_date" = "datetime")) |> 
  mutate(resid = fdom_observed - value,
         Horizon = Horizon*-1) |> 
  filter(Horizon > 0) |> 
  mutate(Julian = yday(forecast_date),
         Season = ifelse(Julian >= 54 & Julian <= 68, "Spring", NA),
         Season = ifelse(Julian >= 69 & Julian <= 307, "Summer", Season),
         Season = ifelse(Julian >= 308 & Julian <= 353, "Fall", Season),
         Season = ifelse(Julian >= 354 | Julian <= 53, "Winter", Season)
         )

#rmse
output_stats |> 
  group_by(Horizon, Season) |> 
  summarise(rmse = round(sqrt(mean((value - fdom_observed)^2, na.rm = TRUE)), 2) ) 

# rmse <- 
output_stats |> 
  group_by(Horizon, Season) |> 
  summarise(rmse = round(sqrt(mean((value - fdom_observed)^2, na.rm = TRUE)), 2) ) |> 
  ggplot(aes(x = Horizon, y = rmse, color = Season))+
  geom_line(linewidth = 1.2)+
  geom_point(size = 3)+
  ggtitle("RMSE by season")+
  theme_bw() + theme(legend.position = "top")

#sd <- 
output_stats |> 
  group_by(Horizon, Season) |> 
  summarise(sd = sd(value, na.rm = T)) |> 
  ggplot(aes(x = Horizon, y = sd, color = Season ))+
  geom_line(linewidth = 1.2)+
  geom_point(size = 3)+
  ggtitle("SD by season")+
  theme_bw() + theme(legend.position = "top")

#resid mean over horizon
output_stats |> 
  group_by(Horizon, Season) |> 
  mutate(resid = mean(resid, na.rm = T) ) |> 
  ggplot(aes(x = Horizon, y = resid, color = Season))+
  geom_line(linewidth = 1.2)+
  geom_point()+
  ggtitle("residual by season")+
  theme_bw()


# #boxplot trial
# output_stats |> 
#   ggplot()+
#   geom_boxplot(aes(x = as.factor(Horizon), y = resid))+
#   # geom_jitter()+
#   ggtitle("residual by season")+
#   theme_bw()

library(patchwork)

# rmse | sd

```










